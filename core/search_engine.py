import numpy as np
import sqlite3
import faiss
from typing import List, Dict, Optional
from datetime import datetime
from math import radians, sin, cos, sqrt, atan2
import json
import logging

class SearchEngine:
    def __init__(self, db_path: str, clip_processor, face_detector):
        self.db_path = db_path
        self.clip_processor = clip_processor
        self.face_detector = face_detector
        
        # FAISS ì¸ë±ìŠ¤
        self.faiss_index = None
        self.id_mapping = []  # FAISS ì¸ë±ìŠ¤ ìœ„ì¹˜ -> image_id ë§¤í•‘
        
        # ë²¡í„° ì°¨ì› (clip_processorì—ì„œ ê°€ì ¸ì˜´)
        self.vector_dim = getattr(clip_processor, 'vector_dim', 768)
        
        # [ì¶”ê°€] ì¿¼ë¦¬ ìœ í˜•ë³„ ë™ì  ì„ê³„ê°’
        self.thresholds = {
            'default': 0.26,
            'food': 0.24,        # ìŒì‹ì€ ì¡°ê¸ˆ ë” ê´€ëŒ€í•˜ê²Œ
            'person': 0.28,     # ì‚¬ëŒì€ ì¢€ ë” ì—„ê²©í•˜ê²Œ
            'place': 0.25,      # ì¥ì†Œ
            'activity': 0.25,   # í™œë™
        }
        
        # ì´ˆê¸° FAISS ì¸ë±ìŠ¤ ë¹Œë“œ
        self._build_faiss_index()
    
    def _build_faiss_index(self):
        """FAISS ì¸ë±ìŠ¤ êµ¬ì¶•"""
        logging.info("ğŸ”¨ FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘...")
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT id, clip_vector FROM images WHERE clip_vector IS NOT NULL
            """)
            
            rows = cursor.fetchall()
            
            if not rows:
                logging.warning("ì¸ë±ì‹±í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ë²¡í„° ìˆ˜ì§‘
            vectors = []
            self.id_mapping = []
            
            for image_id, vector_bytes in rows:
                vector = np.frombuffer(vector_bytes, dtype=np.float32)
                
                # ë²¡í„° ì°¨ì› ê²€ì¦
                if len(vector) != self.vector_dim:
                    logging.warning(f"ì´ë¯¸ì§€ {image_id}: ë²¡í„° ì°¨ì› ë¶ˆì¼ì¹˜ ({len(vector)} != {self.vector_dim})")
                    continue
                
                vectors.append(vector)
                self.id_mapping.append(image_id)
            
            if not vectors:
                logging.warning("ìœ íš¨í•œ ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # numpy ë°°ì—´ë¡œ ë³€í™˜
            vectors_array = np.array(vectors, dtype=np.float32)
            
            # FAISS ì¸ë±ìŠ¤ ìƒì„± (Inner Product = Cosine Similarity for normalized vectors)
            self.faiss_index = faiss.IndexFlatIP(self.vector_dim)
            self.faiss_index.add(vectors_array)
            
            logging.info(f"âœ… FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {len(self.id_mapping)}ê°œ ë²¡í„°")
    
    def rebuild_index(self):
        """ì¸ë±ìŠ¤ ì¬êµ¬ì¶• (ìƒˆ ì´ë¯¸ì§€ ì¶”ê°€ í›„ í˜¸ì¶œ)"""
        self._build_faiss_index()
    
    def _get_dynamic_threshold(self, search_text: str) -> float:
        """[ì¶”ê°€] ê²€ìƒ‰ í…ìŠ¤íŠ¸ ê¸°ë°˜ ë™ì  ì„ê³„ê°’ ê²°ì •"""
        search_lower = search_text.lower()
        
        # ìŒì‹ ê´€ë ¨ í‚¤ì›Œë“œ
        food_keywords = ['food', 'meal', 'eat', 'restaurant', 'pasta', 'pizza', 
                        'steak', 'sushi', 'coffee', 'cake', 'dessert', 'lunch', 
                        'dinner', 'breakfast', 'burger', 'hamburger', 'ramen', 'noodle']
        if any(kw in search_lower for kw in food_keywords):
            return self.thresholds['food']
        
        # ì‚¬ëŒ ê´€ë ¨ í‚¤ì›Œë“œ
        person_keywords = ['person', 'people', 'family', 'friend', 'portrait', 
                          'selfie', 'group', 'face', 'man', 'woman', 'child']
        if any(kw in search_lower for kw in person_keywords):
            return self.thresholds['person']
        
        # ì¥ì†Œ ê´€ë ¨ í‚¤ì›Œë“œ
        place_keywords = ['beach', 'mountain', 'city', 'park', 'building', 
                         'street', 'ocean', 'lake', 'forest', 'bridge', 'casino']
        if any(kw in search_lower for kw in place_keywords):
            return self.thresholds['place']
        
        # í™œë™ ê´€ë ¨ í‚¤ì›Œë“œ
        activity_keywords = ['walking', 'running', 'swimming', 'playing', 
                            'dancing', 'singing', 'cooking', 'reading', 'travel']
        if any(kw in search_lower for kw in activity_keywords):
            return self.thresholds['activity']
        
        return self.thresholds['default']
    
    def search(self, parsed_query: Dict, top_k: int = 10) -> List[Dict]:
        """í†µí•© ê²€ìƒ‰ ì‹¤í–‰"""
        results = []
        
        # 1. ë‚ ì§œ í•„í„°ë§
        date_filtered = self._filter_by_date(
            parsed_query.get('time_range', {})
        )
        
        # 2. ìœ„ì¹˜ í•„í„°ë§ (í•˜ì´ë¸Œë¦¬ë“œ: GPS + ë¬¸ìì—´)
        location_filtered = None
        if parsed_query.get('location'):
            location_filtered = self._filter_by_location_hybrid(
                date_filtered,
                parsed_query['location']
            )
        
        # ğŸ”¥ ìœ„ì¹˜ë§Œ ê²€ìƒ‰ì¸ì§€ íŒë‹¨ (í‚¤ì›Œë“œ ì—†ìŒ)
        has_location = parsed_query.get('location') is not None
        
        # ğŸ”¥ ìœ„ì¹˜ ê´€ë ¨ í‚¤ì›Œë“œëŠ” ì œì™¸í•˜ê³  íŒë‹¨
        keywords = parsed_query.get('keywords', [])
        location_names = []
        if has_location and parsed_query.get('location'):
            location_names = parsed_query['location'].get('names', [])
        
        # ìœ„ì¹˜/ì—¬í–‰ ê´€ë ¨ ì¼ë°˜ í‚¤ì›Œë“œ (ì´ëŸ° ê±´ CLIP ê²€ìƒ‰ ì•ˆ í•´ë„ ë¨)
        generic_keywords = ['ì—¬í–‰', 'travel', 'í’ê²½', 'landscape', 'scenic', 'ê´€ê´‘', 'tour', 
                           'trip', 'vacation', 'ì‚¬ì§„', 'photo', 'picture', 'image',
                           'nature', 'ìì—°', 'view', 'ë·°', 'ê²½ì¹˜', 'island', 'ì„¬']
        
        # ì‹¤ì œ ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œë§Œ í•„í„°ë§
        meaningful_keywords = []
        for kw in keywords:
            kw_lower = kw.lower()
            # ìœ„ì¹˜ëª…ì´ í¬í•¨ëœ í‚¤ì›Œë“œ ì œì™¸ (ì˜ˆ: "ì œì£¼ ì—¬í–‰")
            is_location_related = any(loc.lower() in kw_lower for loc in location_names)
            # ì¼ë°˜ ì—¬í–‰/í’ê²½ í‚¤ì›Œë“œ ì œì™¸
            is_generic = any(g in kw_lower for g in generic_keywords)
            
            if not is_location_related and not is_generic:
                meaningful_keywords.append(kw)
        
        has_keywords = len(meaningful_keywords) > 0
        
        logging.info(f"ğŸ” has_location: {has_location}, has_keywords: {has_keywords}")
        logging.info(f"ğŸ” ì›ë³¸ keywords: {keywords}")
        logging.info(f"ğŸ” ì˜ë¯¸ìˆëŠ” keywords: {meaningful_keywords}")
        
        # 3. ê²€ìƒ‰ ë¶„ê¸°
        if has_location and not has_keywords:
            # ğŸ”¥ ìœ„ì¹˜ë§Œ ê²€ìƒ‰ â†’ CLIP ìŠ¤í‚µ, GPS ê²°ê³¼ ë°”ë¡œ ë°˜í™˜
            logging.info(f"ğŸ“ ìœ„ì¹˜ë§Œ ê²€ìƒ‰ - CLIP ìŠ¤í‚µ, {len(location_filtered)}ì¥ ì¤‘ {top_k}ì¥ ë°˜í™˜")
            
            if location_filtered:
                # ìµœì‹ ìˆœ ì •ë ¬
                sorted_ids = self._sort_by_date_desc(location_filtered, top_k)
                results = [{'id': id, 'similarity': 1.0} for id in sorted_ids]
            else:
                results = []
        
        elif parsed_query.get('search_text'):
            # ìœ„ì¹˜+í‚¤ì›Œë“œ ë˜ëŠ” í‚¤ì›Œë“œë§Œ ê²€ìƒ‰ â†’ CLIP ì‚¬ìš©
            candidate_ids = location_filtered if location_filtered else date_filtered
            
            clip_results = self._search_by_clip_faiss(
                parsed_query['search_text'],
                candidate_ids=candidate_ids
            )
            
            # ë™ì  ì„ê³„ê°’ ì ìš©
            threshold = self._get_dynamic_threshold(parsed_query['search_text'])
            logging.info(f"ğŸ“Š ì ìš©ëœ ìœ ì‚¬ë„ ì„ê³„ê°’: {threshold}")
            
            filtered_results = [r for r in clip_results if r['similarity'] > threshold]
            
            # ì„ê³„ê°’ í†µê³¼í•˜ëŠ” ê²°ê³¼ ì—†ìœ¼ë©´
            if not filtered_results and clip_results:
                # ìµœì†Œ 0.20 ì´ìƒì¼ ë•Œë§Œ 1ë“± ë°˜í™˜
                if clip_results[0]['similarity'] >= 0.20:
                    results = clip_results[:1]
                else:
                    results = []  # ë„ˆë¬´ ë‚®ìœ¼ë©´ ê²°ê³¼ ì—†ìŒ
            else:
                results = filtered_results[:top_k]
        else:
            results = [{'id': id, 'similarity': 0} for id in date_filtered[:top_k]]
        
        # 4. ì‚¬ëŒ í•„í„°ë§
        if parsed_query.get('people'):
            results = self._filter_by_people(
                results,
                parsed_query['people']
            )
        
        # 5. ê²°ê³¼ ì •ë³´ ë³´ê°•
        return self._enrich_results(results)
    
    def _sort_by_date_desc(self, ids: List[int], limit: int) -> List[int]:
        """ğŸ”¥ ë‚ ì§œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (ìµœì‹ ìˆœ)"""
        if not ids:
            return []
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            placeholders = ','.join('?' * len(ids))
            cursor.execute(f"""
                SELECT id FROM images 
                WHERE id IN ({placeholders})
                ORDER BY taken_date DESC
                LIMIT ?
            """, ids + [limit])
            return [row[0] for row in cursor.fetchall()]
    
    def _filter_by_date(self, time_range: Dict) -> List[int]:
        """ë‚ ì§œë¡œ í•„í„°ë§"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            query = "SELECT id FROM images WHERE 1=1"
            params = []
            
            if time_range.get('start'):
                query += " AND taken_date >= ?"
                params.append(time_range['start'])
            
            if time_range.get('end'):
                query += " AND taken_date <= ?"
                params.append(f"{time_range['end']} 23:59:59")
            
            cursor.execute(query, params)
            return [row[0] for row in cursor.fetchall()]
    
    def _filter_by_location_hybrid(self, candidate_ids: List[int], location_data: Dict) -> List[int]:
        """GPS + ë¬¸ìì—´ ë§¤ì¹­ í•˜ì´ë¸Œë¦¬ë“œ ìœ„ì¹˜ í•„í„°ë§"""
        if not candidate_ids:
            return []
        
        gps_filtered = self._filter_by_gps(candidate_ids, location_data)
        string_filtered = self._filter_by_location_name(candidate_ids, location_data)
        
        combined = list(set(gps_filtered + string_filtered))
        
        print(f"ğŸ“ ìœ„ì¹˜ í•„í„°ë§ ê²°ê³¼:")
        print(f"   GPS ë°˜ê²½: {len(gps_filtered)}ì¥")
        print(f"   ë¬¸ìì—´ ë§¤ì¹­: {len(string_filtered)}ì¥")
        print(f"   í•©ê³„: {len(combined)}ì¥")
        
        return combined
    
    def _filter_by_gps(self, candidate_ids: List[int], location_data: Dict) -> List[int]:
        """GPS ì¢Œí‘œ ë°˜ê²½ ë‚´ ì‚¬ì§„ë§Œ"""
        if not candidate_ids or not location_data.get('coordinates'):
            return []
        
        coords = location_data['coordinates']
        target_lat = coords['lat']
        target_lon = coords['lon']
        radius_km = coords.get('radius_km', 5)
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            placeholders = ','.join('?' * len(candidate_ids))
            
            query = f"""
                SELECT id, gps_lat, gps_lon 
                FROM images 
                WHERE id IN ({placeholders})
                AND gps_lat IS NOT NULL 
                AND gps_lon IS NOT NULL
            """
            
            cursor.execute(query, candidate_ids)
            
            filtered_ids = []
            for row in cursor.fetchall():
                image_id, lat, lon = row
                distance = self._haversine_distance(target_lat, target_lon, lat, lon)
                
                if distance <= radius_km:
                    filtered_ids.append(image_id)
            
            return filtered_ids
    
    def _normalize_korean_location(self, name: str) -> List[str]:
        """ğŸ”¥ í•œêµ­ ì§€ì—­ëª… ì •ê·œí™” - ì—¬ëŸ¬ ë³€í˜• ìƒì„±
        ì œì£¼ = ì œì£¼ë„ = ì œì£¼ì‹œ
        ë¶€ì‚° = ë¶€ì‚°ì‹œ = ë¶€ì‚°ê´‘ì—­ì‹œ
        ì„œìš¸ = ì„œìš¸ì‹œ = ì„œìš¸íŠ¹ë³„ì‹œ
        """
        variants = [name]
        
        # ì ‘ë¯¸ì‚¬ ëª©ë¡ (ê¸´ ê²ƒë¶€í„°)
        suffixes = ['íŠ¹ë³„ìì¹˜ë„', 'íŠ¹ë³„ìì¹˜ì‹œ', 'ê´‘ì—­ì‹œ', 'íŠ¹ë³„ì‹œ', 'ìì¹˜ë„', 'ìì¹˜ì‹œ', 'ë„', 'ì‹œ', 'êµ°', 'êµ¬']
        
        # ì ‘ë¯¸ì‚¬ ì œê±°í•œ ë²„ì „ ì¶”ê°€
        base_name = name
        for suffix in suffixes:
            if name.endswith(suffix) and len(name) > len(suffix):
                base_name = name[:-len(suffix)]
                variants.append(base_name)
                break
        
        # ê¸°ë³¸ ì´ë¦„ì— ì ‘ë¯¸ì‚¬ ë¶™ì¸ ë²„ì „ë“¤ ì¶”ê°€
        if base_name != name:
            # "ì œì£¼" â†’ "ì œì£¼ì‹œ", "ì œì£¼ë„" ë“±
            for suffix in ['ì‹œ', 'ë„']:
                variant = base_name + suffix
                if variant not in variants:
                    variants.append(variant)
        
        return list(set(variants))
    
    def _filter_by_location_name(self, candidate_ids: List[int], location_data: Dict) -> List[int]:
        """ë¬¸ìì—´ ë§¤ì¹­ (GPS ì—†ëŠ” ì‚¬ì§„ ëŒ€ë¹„)"""
        if not candidate_ids:
            return []
            
        location_names = location_data.get('names', [])
        if not location_names:
            return []
        
        # ğŸ”¥ í•œêµ­ ì§€ì—­ëª… ì •ê·œí™” ì ìš©
        all_variants = []
        for name in location_names[:2]:  # ìƒìœ„ 2ê°œë§Œ
            variants = self._normalize_korean_location(name)
            all_variants.extend(variants)
        
        # ì¤‘ë³µ ì œê±°
        all_variants = list(set(all_variants))
        logging.info(f"ğŸ“ ìœ„ì¹˜ ê²€ìƒ‰ì–´ ë³€í˜•: {all_variants}")
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            placeholders = ','.join('?' * len(candidate_ids))
            location_conditions = ' OR '.join(['location_name LIKE ?' for _ in all_variants])
            
            query = f"""
                SELECT id FROM images 
                WHERE id IN ({placeholders})
                AND location_name IS NOT NULL
                AND gps_lat IS NULL
                AND gps_lon IS NULL
                AND ({location_conditions})
            """
            
            params = candidate_ids + [f'%{name}%' for name in all_variants]
            cursor.execute(query, params)
            
            return [row[0] for row in cursor.fetchall()]
    
    def _haversine_distance(self, lat1: float, lon1: float, lat2: float, lon2: float) -> float:
        """ë‘ GPS ì¢Œí‘œ ê°„ ê±°ë¦¬ ê³„ì‚° (km)"""
        R = 6371
        
        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        
        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
        c = 2 * atan2(sqrt(a), sqrt(1-a))
        
        return R * c
    
    def _search_by_clip_faiss(self, search_text: str, 
                              candidate_ids: Optional[List[int]] = None) -> List[Dict]:
        """[ì¶”ê°€] FAISSë¥¼ ì‚¬ìš©í•œ ê³ ì† ë²¡í„° ê²€ìƒ‰"""
        
        if self.faiss_index is None or len(self.id_mapping) == 0:
            logging.warning("FAISS ì¸ë±ìŠ¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
            return self._search_by_clip_legacy(search_text, candidate_ids)
        
        # í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
        text_vector = self.clip_processor.encode_text(search_text)
        text_vector = text_vector.reshape(1, -1).astype(np.float32)
        
        # FAISS ê²€ìƒ‰ (ì „ì²´ì—ì„œ top-k ê°€ì ¸ì˜´)
        k = min(100, self.faiss_index.ntotal)
        similarities, indices = self.faiss_index.search(text_vector, k)
        
        results = []
        for sim, idx in zip(similarities[0], indices[0]):
            if idx < 0:
                continue
                
            image_id = self.id_mapping[idx]
            
            # candidate_ids í•„í„°ë§
            if candidate_ids is not None and image_id not in candidate_ids:
                continue
            
            results.append({
                'id': image_id,
                'file_path': None,
                'similarity': float(sim)
            })
        
        results.sort(key=lambda x: x['similarity'], reverse=True)
        
        return results
    
    def _search_by_clip_legacy(self, search_text: str, 
                               candidate_ids: Optional[List[int]] = None) -> List[Dict]:
        """ê¸°ì¡´ SQLite ê¸°ë°˜ ê²€ìƒ‰ (fallback)"""
        text_vector = self.clip_processor.encode_text(search_text)
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            if candidate_ids:
                placeholders = ','.join('?' * len(candidate_ids))
                query = f"""
                    SELECT id, file_path, clip_vector 
                    FROM images 
                    WHERE id IN ({placeholders})
                """
                cursor.execute(query, candidate_ids)
            else:
                cursor.execute("""
                    SELECT id, file_path, clip_vector 
                    FROM images 
                    WHERE clip_vector IS NOT NULL
                """)
            
            results = []
            for row in cursor.fetchall():
                image_id, file_path, clip_vector_bytes = row
                
                image_vector = np.frombuffer(clip_vector_bytes, dtype=np.float32)
                similarity = np.dot(text_vector, image_vector)
                
                results.append({
                    'id': image_id,
                    'file_path': file_path,
                    'similarity': float(similarity)
                })
            
            results.sort(key=lambda x: x['similarity'], reverse=True)
            
            return results
    
    def _filter_by_people(self, results: List[Dict], people: List[str]) -> List[Dict]:
        """ì‚¬ëŒìœ¼ë¡œ í•„í„°ë§"""
        if not results:
            return []
            
        filtered = []
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            for result in results:
                placeholders = ','.join(['?'] * len(people))
                cursor.execute(f"""
                    SELECT person_name 
                    FROM faces 
                    WHERE image_id = ? AND person_name IN ({placeholders})
                """, [result['id']] + people)
                
                if cursor.fetchone():
                    filtered.append(result)
        
        return filtered
    
    def _enrich_results(self, results: List[Dict]) -> List[Dict]:
        """ê²€ìƒ‰ ê²°ê³¼ì— ë©”íƒ€ë°ì´í„° ì¶”ê°€"""
        if not results:
            return []
            
        enriched = []
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            for result in results:
                cursor.execute("""
                    SELECT file_path, thumbnail_path, taken_date, 
                           location_name, metadata
                    FROM images 
                    WHERE id = ?
                """, (result['id'],))
                
                row = cursor.fetchone()
                if row:
                    enriched.append({
                        'id': result['id'],
                        'file_path': row[0],
                        'thumbnail_path': row[1],
                        'taken_date': row[2],
                        'location_name': row[3],
                        'metadata': json.loads(row[4]) if row[4] else {},
                        'similarity': result.get('similarity', 0)
                    })
        
        return enriched